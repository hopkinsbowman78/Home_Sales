# sparksql-views-temp-tables

In this challenge, I used my knowledge of SparkSQL to determine key metrics about home sales data. Then I used Spark to create temporary views, partition the data, cache and uncache a temporary table, and verify that the table has been uncached.

## Table of Contents
- Home_Sales_starter_code_colab.ipynb
- Home_Sales.ipynb (Final Code completed in Colab)

## Documentation
SparkSQL documentation (https://spark.apache.org/docs/latest/sql-ref.html)  
Colab documentation (https://colab.research.google.com/)  
Parquet documentation (https://parquet.apache.org/docs/)
